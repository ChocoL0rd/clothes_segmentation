{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72dfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raph/fast_mem/anaconda3/envs/ImgSegment/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToPILImage\n",
    "tensor2pil = ToPILImage()\n",
    "\n",
    "from tools.dataset_tools import *\n",
    "from tools.model_tools import *\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48baa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"outputs\"\n",
    "exp_paths = [\n",
    "    os.path.join(\"2023-05-23\", \"04-30-01\"),\n",
    "    os.path.join(\"2023-05-24\", \"16-24-53\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05646843",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metric = \"soft_jaccard\"\n",
    "metric_value = 0.85\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8574f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cfg = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"path\": \"../datasets/datasets.json\",\n",
    "    \"max_subset_size\": -1,\n",
    "    \n",
    "    \"bgr_trfm\": [],\n",
    "    \"fgr_trfm\": [],\n",
    "    \"trfm\": [],\n",
    "    \"preproc\": [],\n",
    "}\n",
    "\n",
    "with open(dataset_cfg[\"path\"]) as f:\n",
    "    file_dict = json.load(f)\n",
    "\n",
    "data_path = os.path.join(os.path.dirname(dataset_cfg[\"path\"]), file_dict[\"root_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b779036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    \"name\": \"mini_u2net\",\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"load_pretrained\": True,\n",
    "    \"pretrained_path\": \"\",\n",
    "    \n",
    "    \"freeze_encoder\": [False, False, False, False, False, False],\n",
    "    \"freeze_decoder\": [False, False, False, False, False],\n",
    "    \"freeze_side\": [False, False, False, False, False, False],\n",
    "\n",
    "    \"out_ch\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1aec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate(model, loader, save_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for dir_names, img_names, img_batch, mask_batch in tqdm.tqdm(loader):\n",
    "            predicted_batch = model.inference(img_batch)[0]\n",
    "\n",
    "            masked_batch = img_batch * predicted_batch\n",
    "            for i, masked_tensor in enumerate(masked_batch):\n",
    "                masked_pil = tensor2pil(masked_tensor)\n",
    "                masked_pil.save(os.path.join(save_path, dir_names[i], img_names[i] + \".jpg\"))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab8d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [00:51<00:00,  2.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:25<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"bad_pictures\" \n",
    "\n",
    "for exp_path in exp_paths:\n",
    "    save_path = os.path.join(save_dir, exp_path) # куда сохраняем\n",
    "    # пересоздаем если есть\n",
    "    if os.path.exists(save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "    # подгружаем обученную модель\n",
    "    model_cfg[\"pretrained_path\"] = os.path.join(root_path, exp_path)\n",
    "    model = cfg2model(model_cfg)\n",
    "    \n",
    "    # делаем словарь с плохими изображениями\n",
    "    test_df = pd.read_excel(os.path.join(root_path, exp_path, \"test\", \"full_results.xlsx\"))\n",
    "    bad_pictures = test_df[test_df[target_metric] < metric_value][[\"dir\", \"img\"]]\n",
    "    \n",
    "    dir_dict = {}\n",
    "    for dir_name in bad_pictures[\"dir\"].unique():\n",
    "        os.makedirs(os.path.join(save_path, dir_name))\n",
    "        dir_dict[dir_name] = bad_pictures[bad_pictures[\"dir\"] == dir_name][\"img\"].tolist()\n",
    "    \n",
    "    # создаем датасет, даталоадер с плохими изображениями\n",
    "    testset = MultiImgMaskSet(\n",
    "        log_name=\"test\", root_path=data_path,\n",
    "        dir_dict=dir_dict, max_subset_size=-1,\n",
    "        bgr_trfm=A.Compose([]), fgr_trfm=A.Compose([]), trfm=A.Compose([]), preproc=A.Compose([]),\n",
    "        device=torch.device(dataset_cfg[\"device\"])\n",
    "    )\n",
    "    loader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "    illustrate(model, loader, save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"resized_bad_pictures\" \n",
    "\n",
    "for exp_path in exp_paths:\n",
    "    save_path = os.path.join(save_dir, exp_path) # куда сохраняем\n",
    "    # пересоздаем если есть\n",
    "    if os.path.exists(save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "    # подгружаем обученную модель\n",
    "    model_cfg[\"pretrained_path\"] = os.path.join(root_path, exp_path)\n",
    "    model = cfg2model(model_cfg)\n",
    "    \n",
    "    # делаем словарь с плохими изображениями\n",
    "    test_df = pd.read_excel(os.path.join(root_path, exp_path, \"test\", \"full_results.xlsx\"))\n",
    "    bad_pictures = test_df[test_df[target_metric] < metric_value][[\"dir\", \"img\"]]\n",
    "    \n",
    "    dir_dict = {}\n",
    "    for dir_name in bad_pictures[\"dir\"].unique():\n",
    "        os.makedirs(os.path.join(save_path, dir_name))\n",
    "        dir_dict[dir_name] = bad_pictures[bad_pictures[\"dir\"] == dir_name][\"img\"].tolist()\n",
    "    \n",
    "    # создаем датасет, даталоадер с плохими изображениями\n",
    "    testset = MultiImgMaskSet(\n",
    "        log_name=\"test\", root_path=data_path,\n",
    "        dir_dict=dir_dict, max_subset_size=-1,\n",
    "        bgr_trfm=A.Compose([]), fgr_trfm=A.Compose([]), trfm=A.Compose([]), preproc=A.Compose([]),\n",
    "        device=torch.device(dataset_cfg[\"device\"])\n",
    "    )\n",
    "    loader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "    illustrate(model, loader, save_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
